{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from emoji_utils import *\n",
    "import emoji\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_csv(filename='data/emojify_data.csv'):\n",
    "    with open(filename) as f:\n",
    "        csvfile=csv.reader(f)\n",
    "        phrases=[]\n",
    "        emoji=[]\n",
    "        for row in csvfile:\n",
    "            phrases.append(row[0])\n",
    "            emoji.append(row[1])\n",
    "    X=np.asarray(phrases)\n",
    "    Y=np.asarray(emoji,dtype=int)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, Y_train = read_csv('data/train_emoji.csv')\n",
    "X_test, Y_test = read_csv('data/tesss.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am so impressed by your dedication to this project\n"
     ]
    }
   ],
   "source": [
    "maxstring=max(X_train,key=len)\n",
    "print(maxstring)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#in this maxstring above the maxlen i.e the total no.of words \n",
    "maxlen=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Y_oh_train=convert_to_one_hot(Y_train,5)\n",
    "Y_oh_test=convert_to_one_hot(Y_test,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words_to_index,index_to_words,words_to_vec_map=read_glove_files(\"data/glove.6B.50d.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algo-1 -Using averages of the word embeddings in each sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    \"\"\"Converts a sentence (string) into a list of words (strings). Extracts the GloVe representation of each word\n",
    "    and averages its value into a single vector encoding the meaning of the sentence.\"\"\"\n",
    "    words=sentence.lower().split()\n",
    "    avg=np.zeros((50,))\n",
    "    for word in words:\n",
    "        avg+=word_to_vec_map[word]\n",
    "    avg=avg/len(words)\n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(X,Y,word_to_vec_map,learning_rate=0.01,iterations=1000):\n",
    "    n_y=5\n",
    "    n_h=50\n",
    "    m=X.shape[0]\n",
    "    \n",
    "    #initialization of weight parameters\n",
    "    W=np.random.randn(n_y,n_h)/np.sqrt(n_h)\n",
    "    b=np.zeros((n_y,))\n",
    "    \n",
    "    #convert y to one hot vector\n",
    "    Y_oh=convert_to_one_hot(Y,n_y)\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        cost=0\n",
    "        for j in range(m):\n",
    "            avg=sentence_to_avg(X[j], word_to_vec_map)\n",
    "            \n",
    "            #forwardprop\n",
    "            z=np.dot(W,avg)+b\n",
    "            a=softmax1(z)\n",
    "            \n",
    "            cost=(np.dot(-Y_oh[j],np.log(a)))\n",
    "            \n",
    "            #backprop\n",
    "            dz=a-Y_oh[j]\n",
    "            dW=np.dot(dz.reshape(n_y,1),avg.reshape(1,n_h))\n",
    "            db=dz\n",
    "            \n",
    "            \n",
    "            #update\n",
    "            W=W-learning_rate*dW\n",
    "            b=b-learning_rate*b\n",
    "        if (i%100==0):\n",
    "            print(\"the cost is at iteration {0} is {1}\".format(i,cost))\n",
    "    pred=predict(X,Y,W,b,word_to_vec_map)\n",
    "    \n",
    "    return pred,W,b        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict(X,Y,W,b,word_to_vec_map):\n",
    "    pred=np.zeros((X.shape[0],1))\n",
    "    for i in range(X.shape[0]):\n",
    "        avg=np.zeros((50,))\n",
    "        line=X[i].lower().split()\n",
    "        for words in line:\n",
    "            avg+=words_to_vec_map[words]\n",
    "        avg=avg/len(line)\n",
    "        \n",
    "        a=np.dot(W,avg)+b\n",
    "        z=softmax1(a)\n",
    "        pred[i,0]=np.argmax(z)\n",
    "    print(\"Accuracy:{0}\".format(np.mean(pred[:]==Y.reshape(Y.shape[0],1)[:])*100))\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the cost is at iteration 0 is 1.6195359767984308\n",
      "the cost is at iteration 100 is 0.07588644356426631\n",
      "the cost is at iteration 200 is 0.04625652902330257\n",
      "the cost is at iteration 300 is 0.03712218934625889\n",
      "the cost is at iteration 400 is 0.03199076902152221\n",
      "the cost is at iteration 500 is 0.02834752242137004\n",
      "the cost is at iteration 600 is 0.02549950429889686\n",
      "the cost is at iteration 700 is 0.023173449849686462\n",
      "the cost is at iteration 800 is 0.02123047879843488\n",
      "the cost is at iteration 900 is 0.01958640511707976\n",
      "Accuracy:98.48484848484848\n"
     ]
    }
   ],
   "source": [
    "pred,W,b=model(X_train,Y_train,words_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:91.07142857142857\n"
     ]
    }
   ],
   "source": [
    "pred_test=predict(X_test,Y_test,W,b,words_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emoji_dictionary = {\"0\": \"\\u2764\\uFE0F\",    # :heart: prints a black instead of red heart depending on the font\n",
    "                    \"1\": \":baseball:\",\n",
    "                    \"2\": \":smile:\",\n",
    "                    \"3\": \":disappointed:\",\n",
    "                    \"4\": \":fork_and_knife:\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I want to eat\t üç¥\n",
      "he did not answer\t :disappointed:\n",
      "he got a very nice raise\t :smile:\n",
      "she got me a nice present\t :smile:\n",
      "ha ha ha it was so funny\t :smile:\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    m=Y_test[i]\n",
    "    print(X_test[i],label_to_emoji(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öæ\n"
     ]
    }
   ],
   "source": [
    "print(emoji.emojize(\":baseball:\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:100.0\n"
     ]
    }
   ],
   "source": [
    "X_my_sentences = np.array([\"i adore you\", \"i love you\", \"funny lol\", \"lets play with a ball\", \"food is ready\", \"not feeling happy\"])\n",
    "Y_my_labels = np.array([[0], [0], [2], [1], [4],[3]])\n",
    "\n",
    "pred = predict(X_my_sentences, Y_my_labels , W, b, words_to_vec_map)\n",
    "#print_predictions(X_my_sentences, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(Y_my_labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56,)\n",
      "           ‚ù§Ô∏è    ‚öæ    :smile:    :disappointed:   üç¥\n",
      "Predicted  0.0  1.0  2.0  3.0  4.0  All\n",
      "Actual                                 \n",
      "0            6    0    0    1    0    7\n",
      "1            0    8    0    0    0    8\n",
      "2            1    0   17    0    0   18\n",
      "3            1    1    1   13    0   16\n",
      "4            0    0    0    0    7    7\n",
      "All          8    9   18   14    7   56\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAFRCAYAAABUjkf3AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7c7790cbe0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Y_test.shape)\n",
    "print('           '+ label_to_emoji(0)+ '    ' + label_to_emoji(1) + '    ' +  label_to_emoji(2)+ '    ' + label_to_emoji(3)+'   ' + label_to_emoji(4))\n",
    "print(pd.crosstab(Y_test, pred_test.reshape(56,), rownames=['Actual'], colnames=['Predicted'], margins=True))\n",
    "plot_confusion_matrix(Y_test, pred_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using LSTMS in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras Minibatch\n",
    "\n",
    "The common solution is padding because we can vectorize over the entire training set if all of them have the \n",
    "same sentence length ,so that the no. of blocks required in each LSTM layer will be same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Embedding Layer\n",
    "\n",
    "This layer converts every word in the sentence to its word embeddings which will acts as an input to the network.So in keras it is done by embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#converts each sentence to its corresponding indices equivalent which can be given as an input to the \n",
    "#embedding layer\n",
    "def sentences_to_index(X,word_to_index,maxlen):\n",
    "    m=X.shape[0]\n",
    "    X_indices=np.zeros((m,maxlen))\n",
    "    for i in range(m):\n",
    "        sent_words=X[i].lower().split()\n",
    "        j=0\n",
    "        for w in sent_words:\n",
    "            X_indices[i,j]=word_to_index[w]\n",
    "            j+=1\n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    emb_dim=word_to_vec_map[\"cucumber\"].shape[0]\n",
    "    vocab_length=len(word_to_vec_map)+1\n",
    "    emb_matrix=np.zeros((vocab_length,emb_dim))\n",
    "    words=word_to_vec_map.keys()\n",
    "    for w in words:\n",
    "        idx=word_to_index[w]\n",
    "        emb_matrix[idx,:]=word_to_vec_map[w]\n",
    "    embedding_layer=Embedding(input_dim=vocab_length,output_dim=emb_dim,trainable=False)#trainable is set to False cause during optimization it will not be trained further\n",
    "    embedding_layer.build((None,))\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "embedding_layer = pretrained_embedding_layer(words_to_vec_map, words_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def emojify_v2(input_shape,word_to_vec_map,word_to_index):\n",
    "    sentence_indices=Input(input_shape)\n",
    "    embedding_layer=pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    embeddings=embedding_layer(sentence_indices)\n",
    "    X=LSTM(units=128,return_sequences=True)(embeddings)\n",
    "    X=Dropout(0.5)(X)\n",
    "    X=LSTM(units=128)(X)\n",
    "    X=Dropout(0.5)(X)\n",
    "    X=Dense(units=5)(X)\n",
    "    X=Activation('softmax')(X)\n",
    "    model=Model(input=sentence_indices,output=X)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 223,877\n",
      "Non-trainable params: 20,000,050\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ajita/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:11: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"ac..., inputs=Tensor(\"in...)`\n"
     ]
    }
   ],
   "source": [
    "model=emojify_v2((maxlen,),words_to_vec_map,words_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_indices = sentences_to_index(X_train, words_to_index, maxlen)\n",
    "Y_train_oh = convert_to_one_hot(Y_train, C = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 2s 18ms/step - loss: 1.6041 - acc: 0.2045\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.5244 - acc: 0.3485\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4970 - acc: 0.3561\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.4458 - acc: 0.4394\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.3681 - acc: 0.4091\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.2994 - acc: 0.5303\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.1139 - acc: 0.6136\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 1.0091 - acc: 0.6742\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.9229 - acc: 0.6667\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.8209 - acc: 0.7121\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.6416 - acc: 0.7727\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.5474 - acc: 0.8409\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.6103 - acc: 0.7955\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4982 - acc: 0.8561\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4055 - acc: 0.8333\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4616 - acc: 0.8106\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4722 - acc: 0.8333\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4238 - acc: 0.8561\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.4048 - acc: 0.8788\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3543 - acc: 0.8939\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.4247 - acc: 0.8636\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2963 - acc: 0.9015\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2828 - acc: 0.9015\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2495 - acc: 0.9242\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1857 - acc: 0.9621\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2230 - acc: 0.9242\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1466 - acc: 0.9394\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0977 - acc: 0.9697\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0918 - acc: 0.9697\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0716 - acc: 0.9773\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9697\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0716 - acc: 0.9848\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1105 - acc: 0.9545\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1127 - acc: 0.9697\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.2263 - acc: 0.9394\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3811 - acc: 0.8864\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2890 - acc: 0.9091\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.3034 - acc: 0.8864\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.3771 - acc: 0.8333\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.2275 - acc: 0.9318\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.1567 - acc: 0.9697\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1150 - acc: 0.9924\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.1290 - acc: 0.9621\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0775 - acc: 0.9848\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0757 - acc: 0.9924\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0596 - acc: 0.9924\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0857 - acc: 0.9773\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0707 - acc: 0.9697\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 0s 2ms/step - loss: 0.0691 - acc: 0.9697\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 0s 1ms/step - loss: 0.0502 - acc: 0.9848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7c73b64e80>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train_indices,Y_train_oh,epochs=50,batch_size=32,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 4ms/step\n",
      "\n",
      "Test accuracy:0.8214285714285714\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_index(X_test, words_to_index, maxlen = maxlen)\n",
    "Y_test_oh = convert_to_one_hot(Y_test, C = 5)\n",
    "loss,acc=model.evaluate(X_test_indices,Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy:{0}\".format(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji :smile: prediction: he got a very nice raise\t ‚ù§Ô∏è\n",
      "Expected emoji :smile: prediction: she got me a nice present\t ‚ù§Ô∏è\n",
      "Expected emoji :disappointed: prediction: work is hard\t :smile:\n",
      "Expected emoji :disappointed: prediction: This girl is messing with me\t ‚ù§Ô∏è\n",
      "Expected emoji :disappointed: prediction: work is horrible\t :smile:\n",
      "Expected emoji üç¥ prediction: any suggestions for dinner\t :smile:\n",
      "Expected emoji :disappointed: prediction: she is a bully\t ‚ù§Ô∏è\n",
      "Expected emoji ‚ù§Ô∏è prediction: I love you to the stars and back\t :smile:\n",
      "Expected emoji :disappointed: prediction: go away\t ‚öæ\n",
      "Expected emoji :disappointed: prediction: yesterday we lost again\t ‚öæ\n"
     ]
    }
   ],
   "source": [
    "#to visualize the incorect labelled examples\n",
    "pred=model.predict(X_test_indices)\n",
    "for i in range(X_test_indices.shape[0]):\n",
    "    idx=np.argmax(pred[i])\n",
    "    if (idx!=Y_test[i]):\n",
    "        print(\"Expected emoji {0} prediction: {1} {2}\".format(label_to_emoji(Y_test[i]),X_test[i],\n",
    "                                                              label_to_emoji(idx)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
